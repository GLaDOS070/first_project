{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd7d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import lxml\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "import pandas as pd\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4863ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# указать пользователя\n",
    "user = 'MerinovDV'\n",
    "path_to_credential = f'C:/Users/{user}/Downloads/auto-monitoring-367212-64ec4ad9d3a5.json' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89872bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данные для доступа к Google Spreadsheets\n",
    "\n",
    "# Specify path to your file with credentials\n",
    "path_to_credential = path_to_credential \n",
    "\n",
    "# Specify name of table in google sheets\n",
    "table_name = 'Сбор данных для презы hh2022'\n",
    "\n",
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(path_to_credential, scope)\n",
    "\n",
    "gs = gspread.authorize(credentials)\n",
    "work_table = gs.open(table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036638cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url, folder, user, add_folder=None, prof_obl=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    функция проходит с помощью selenium по всем ссылкам, считает кол-во страниц и на основании этого собирает\n",
    "    все страницы с вакансиями для заданного запроса. После этого сохраняет страницы в папки\n",
    "    \n",
    "    url - str, ссылка с запросом\n",
    "    folder - str, название папки\n",
    "    prof_obl - boolб если парсим из вкладки профобласти - True\n",
    "    user - str, текущий пользователь\n",
    "    \"\"\"\n",
    "    \n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:84.0) Gecko/20100101 Firefox/84.0\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "    s = Service(executable_path=f\"C:/Users/{user}/Parsing_folder/chromedriver/chromedriver.exe\")\n",
    "    driver = webdriver.Chrome(service=s, options=options)\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        try:\n",
    "            pages = int(soup.find_all(attrs={'class':'bloko-button','rel': 'nofollow', 'data-qa':'pager-page'})[-1].getText())\n",
    "        except:\n",
    "            pages = 1\n",
    "        for page in range(pages):\n",
    "            if prof_obl:\n",
    "                driver.get(url+ '?page=' + str(page))\n",
    "                time.sleep(0.25)\n",
    "            else:\n",
    "                driver.get(url+ '&page=' + str(page))\n",
    "                time.sleep(0.25)\n",
    "            \n",
    "            if add_folder is not None:\n",
    "                with open(f\"C:/Users/{user}/hh/{add_folder}/{folder}/page_{page}_{date.today()}.html\", \n",
    "                            \"w\", encoding='utf-8') as file:\n",
    "                    file.write(driver.page_source)\n",
    "            else:\n",
    "                with open(f\"C:/Users/{user}/hh/{folder}/page_{page}_{date.today()}.html\", \n",
    "                            \"w\", encoding='utf-8') as file:\n",
    "                    file.write(driver.page_source)\n",
    "    except Exception as ex:\n",
    "                print(ex)\n",
    "\n",
    "    finally:\n",
    "        driver.close()\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e73ea1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_vacancy(folder, user, add_folder=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    вовзращает список с ссылками на на вакансии\n",
    "    folder - str, название папки\n",
    "    user - str, текущий пользователь\n",
    "    \"\"\"\n",
    "    \n",
    "    links_list = []\n",
    "    if add_folder is None:\n",
    "        path = f\"C:/Users/{user}/hh/{folder}\"\n",
    "    else:\n",
    "        path = f\"C:/Users/{user}/hh/{add_folder}/{folder}\"\n",
    "    for html in os.listdir(path):\n",
    "        with open(f\"{path}/{html}\", encoding='utf-8') as file:\n",
    "            src = file.read()\n",
    "\n",
    "            try:\n",
    "                soup = BeautifulSoup(src, \"lxml\")\n",
    "                result = soup.find_all(\"a\", class_=\"serp-item__title\")\n",
    "                if len(result) != 0:\n",
    "                    for i in range(len(result)):\n",
    "                        link = result[i].get('href')\n",
    "                        links_list.append(link)\n",
    "                else:\n",
    "                    print(f'[INFO_PARSER] нет данных по вакансиям {html}')\n",
    "\n",
    "            except:\n",
    "                print('[INFO] проблема с парсингом soup')  \n",
    "    return links_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93091de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vacancy_info(dict_with_links_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    функция возвращает DataFrame с описанием вакансии\n",
    "    dict_with_links_list - dict, словарь, в котором ключ - папка, а значение список ссылок на вакансии по заданному ключу\n",
    "    \"\"\"\n",
    "    \n",
    "    headers = {\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\"}\n",
    "    \n",
    "    dict_with_df = {}\n",
    "    \n",
    "    for key in dict_with_links_list:\n",
    "        name = []\n",
    "        salary_from = []\n",
    "        salary_to = []\n",
    "        salary_currency = []\n",
    "        salary_gross = []\n",
    "        experience_name = []\n",
    "        schedule_name = []\n",
    "        employment_name = []\n",
    "        description = []\n",
    "        key_skills = []\n",
    "        employer = []\n",
    "        published_at = []\n",
    "        url = []\n",
    "        views = []\n",
    "        \n",
    "        for link in tqdm(dict_with_links_list[key]):\n",
    "            flag = False\n",
    "            retry = 0\n",
    "            while flag == False:\n",
    "                r = requests.get(link, headers=headers).text\n",
    "                soup = BeautifulSoup(r, 'lxml')\n",
    "                if soup.find(attrs={'data-qa': 'vacancy-title'}) is not None:\n",
    "                    \n",
    "                    # название вакансии\n",
    "                    title = soup.find(attrs={'data-qa': 'vacancy-title'})\n",
    "                    if title is not None:\n",
    "                        name.append(title.getText())\n",
    "                    else:\n",
    "                        name.append('null')\n",
    "\n",
    "                    # зарплата\n",
    "                    salary = soup.find(attrs={'data-qa': 'vacancy-salary'})\n",
    "                    if salary is not None:\n",
    "                        salary = salary.getText().replace(u'\\xa0', u'').split(' ')\n",
    "                        if 'от' in salary:\n",
    "                            salary_from_i = salary.index('от') + 1\n",
    "                            salary_from.append(salary[salary_from_i])\n",
    "                        else:\n",
    "                            salary_from.append('null')\n",
    "                        if 'до' in salary:\n",
    "                            salary_to_i = salary.index('до') + 1\n",
    "                            if salary[salary_to_i] == 'вычета':\n",
    "                                salary_to.append('null')\n",
    "                            else:\n",
    "                                salary_to.append(salary[salary_to_i])\n",
    "                        else:\n",
    "                            salary_to.append('null')\n",
    "                    else:\n",
    "                        salary_from.append('null')\n",
    "                        salary_to.append('null')\n",
    "\n",
    "                    # валюта\n",
    "                    sal_currency = soup.find(attrs={'data-qa': 'vacancy-salary'})\n",
    "                    if sal_currency is not None:\n",
    "                        sal_currency = sal_currency.getText().split(' ')\n",
    "                        if 'руб.' in sal_currency:\n",
    "                            currency = 'RUB'\n",
    "                        elif 'USD' in sal_currency:\n",
    "                            currency = 'USD'\n",
    "                        elif 'EUR' in sal_currency:\n",
    "                            currency = 'EUR'\n",
    "                        elif 'KZT' in sal_currency:\n",
    "                            currency = 'KZT'\n",
    "                        elif 'бел. руб' in sal_currency:\n",
    "                            currency = 'BYN'\n",
    "                        elif 'KGS' in sal_currency:\n",
    "                            currency = 'KGS'\n",
    "                        elif 'сум' in sal_currency:\n",
    "                            currency = 'UZS'\n",
    "                        elif 'AZN' in sal_currency:\n",
    "                            currency = 'AZN'\n",
    "                        else:\n",
    "                            currency = 'null'\n",
    "                        salary_currency.append(currency)\n",
    "                    else:\n",
    "                        salary_currency.append('null')\n",
    "\n",
    "                    # тип зарплаты\n",
    "                    salary_type = soup.find('span', attrs={'class': 'vacancy-salary-compensation-type'})\n",
    "                    if salary_type is not None:\n",
    "                        salary_gross.append(salary_type.getText().strip())\n",
    "                    else: \n",
    "                            salary_gross.append('null')\n",
    "\n",
    "                    # experience_name\n",
    "                    experience = soup.find(attrs={'data-qa': 'vacancy-experience'})\n",
    "                    if experience is not None:\n",
    "                        experience_name.append(experience.getText())\n",
    "                    else: \n",
    "                        experience_name.append('null')\n",
    "\n",
    "                    # employment_name, schedule_name\n",
    "                    employment_schedule = soup.find(attrs={'data-qa': 'vacancy-view-employment-mode'})\n",
    "                    if employment_schedule is not None:\n",
    "                        employment_name.append(employment_schedule.getText().split(', ')[0])\n",
    "                        schedule_name.append(employment_schedule.getText().split(', ')[1])\n",
    "                    else: \n",
    "                        employment_name.append('null')\n",
    "                        schedule_name.append('null')\n",
    "\n",
    "                    # описание вакансии\n",
    "                    descrip = soup.find('div', class_='vacancy-section')\n",
    "                    if descrip is not None:\n",
    "                        description.append(descrip.getText())\n",
    "                    else:\n",
    "                        description.append('null')\n",
    "\n",
    "                    # key_skills\n",
    "                    key_skills_i = []\n",
    "                    skills = soup.find_all(attrs={'class': 'bloko-tag bloko-tag_inline'})\n",
    "                    if len(skills) != 0:\n",
    "                        for i in soup.find_all(attrs={'class': 'bloko-tag bloko-tag_inline'}):\n",
    "                            key_skills_i.append(i.getText())\n",
    "                        key_skills.append(key_skills_i)\n",
    "                    else:\n",
    "                        key_skills.append('null')\n",
    "\n",
    "                    # название компании\n",
    "                    emp = soup.find('span', class_='vacancy-company-name')\n",
    "                    if emp is not None:\n",
    "                        employer.append(emp.getText())\n",
    "                    else:\n",
    "                        employer.append('null')\n",
    "\n",
    "                    # кол-во просмотров сейчас\n",
    "                    view = soup.find('span', class_='vacancy-viewers-count')\n",
    "                    if view is not None:\n",
    "                        views.append(view.getText().replace(u'\\xa0', u' ').split(' ')[0])\n",
    "                    else:\n",
    "                        views.append('null')\n",
    "\n",
    "                    # опубликована\n",
    "                    dt = soup.find('p', class_='vacancy-creation-time-redesigned')\n",
    "                    if dt is not None:\n",
    "                        published_at.append(dt.getText().replace(u'\\xa0', u' ')\\\n",
    "                                                    .split('опубликована')[1]\\\n",
    "                                                    .split('в')[0].strip())\n",
    "                    else:\n",
    "                        published_at.append('null')\n",
    "\n",
    "                    url.append(link)\n",
    "\n",
    "                    time.sleep(0.25)\n",
    "\n",
    "                    \n",
    "                    flag = True\n",
    "\n",
    "                    \n",
    "                retry += 1\n",
    "                if retry == 5:\n",
    "                    break\n",
    "\n",
    "        output = pd.DataFrame()\n",
    "        output['name'] = name\n",
    "        output['salary_from'] = salary_from\n",
    "        output['salary_to'] = salary_to\n",
    "        output['salary_currency'] = salary_currency\n",
    "        output['salary_gross'] = salary_gross\n",
    "        output['experience_name'] = experience_name\n",
    "        output['schedule_name'] = schedule_name\n",
    "        output['employment_name'] = employment_name\n",
    "        output['description'] = description\n",
    "        output['key_skills'] = key_skills\n",
    "        output['employer'] = employer\n",
    "        output['published_at'] = published_at\n",
    "        output['url'] = url\n",
    "        output['views'] = views\n",
    "        output['type'] = key\n",
    "        \n",
    "        dict_with_df[key] = output\n",
    "\n",
    "    return dict_with_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48db2ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение словаря с кол-вом ключевых навыков\n",
    "def count_skills(column, to_df=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    функция возвращает словарь: ключ - навык, значение - кол-во в выгрузке\n",
    "    \n",
    "    column - столбец в df, который содержит ключевые навыки\n",
    "    to_df - bool, если\n",
    "                    True - возвращает df\n",
    "                    False - возвращает словарь\n",
    "    \"\"\"\n",
    "    dct = {}\n",
    "    for skill_list in column:\n",
    "        for skill in skill_list:\n",
    "            if skill not in dct.keys():\n",
    "                dct[skill] = 1\n",
    "            elif skill in dct.keys():\n",
    "                dct[skill] += 1\n",
    "    if to_df:\n",
    "        df_skills = pd.DataFrame.from_dict(dct, orient='index')\\\n",
    "            .rename(columns={0:'num_skills'})\\\n",
    "            .sort_values('num_skills', ascending=False)\n",
    "        return df_skills\n",
    "    else:\n",
    "        return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4a235c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_df(df, google_sheet, create_sheet=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    функция загружает df в Google Spreadsheets\n",
    "    \n",
    "    df - DataFrame\n",
    "    google_sheet - str, навзание листа\n",
    "    create_sheet - bool, если\n",
    "                    True - создает новый лист\n",
    "                    False - загружает данные в текущий лист\n",
    "    \"\"\"\n",
    "    \n",
    "    df.key_skills = df.key_skills.astype('str')\n",
    "    df.description = df.description.str.replace(u'\\xa0', u' ').str.strip().str.replace(u'\\n', u' ')\n",
    "    \n",
    "    if create_sheet:\n",
    "        ws = work_table.add_worksheet(title=google_sheet, rows=100, cols=20)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    worksheet = work_table.worksheet(google_sheet)\n",
    "    worksheet.append_row(df.columns.tolist(), value_input_option='USER_ENTERED')\n",
    "    worksheet.append_rows(df.values.tolist(), value_input_option='USER_ENTERED')\n",
    "    \n",
    "    return print (f'Данные загружены на лист {google_sheet}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b3846a",
   "metadata": {},
   "source": [
    "# Пример выгрузки вакансий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e801d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  Системный аналитик  Created \n",
      "Directory  Бизнес - аналитик  Created \n",
      "Directory  Аналитик 1С  Created \n",
      "Directory  Аналитик данных  Created \n",
      "Directory  Аналитик информационной безопасности  Created \n",
      "Directory  Маркетолог-аналитик  Created \n",
      "Directory  Продуктовый аналитик  Created \n",
      "Directory  Data scientist  Created \n",
      "Directory  BI аналитик  Created \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1157/1157 [16:13<00:00,  1.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 879/879 [12:17<00:00,  1.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 424/424 [05:56<00:00,  1.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 259/259 [03:33<00:00,  1.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:40<00:00,  1.17it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 137/137 [01:51<00:00,  1.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 163/163 [02:13<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 199/199 [02:40<00:00,  1.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 87/87 [01:08<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Получаем список ссылок\n",
    "worksheet = work_table.worksheet('Ссылки')\n",
    "val = worksheet.get_values('B204:C213')\n",
    "columns = val.pop(0)\n",
    "val = pd.DataFrame(val, columns=columns)\n",
    "\n",
    "# создаем из них словарь\n",
    "g_links_2 = dict(zip(val['название'].values, val['ссылки'].values))\n",
    "\n",
    "# название папки для выгрузки\n",
    "add_folder = 'аналитика'\n",
    "\n",
    "# создаем папки для страниц, если таких папок еще не было\n",
    "for new_folder in val['название'].values:\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir(f'C:/Users/{user}/hh/{add_folder}/{new_folder}')\n",
    "        print(\"Directory \" , new_folder ,  \" Created \") \n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , new_folder ,  \" already exists\")\n",
    "        \n",
    "# проходим по всем ключам словаря (папка - url) и вызываем функцию\n",
    "for key in g_links_2:\n",
    "    get_links(g_links_2[key], key, add_folder=add_folder, user=user)\n",
    "    \n",
    "# создаем новый словарь, в котором ключ - папка, а значение список ссылок на вакансии по заданному ключу\n",
    "dict_with_links_list_g_2 = {}\n",
    "for key in g_links_2:\n",
    "    dict_with_links_list_g_2[key] = get_list_of_vacancy(key, add_folder=add_folder, user=user)\n",
    "    \n",
    "all_df = get_vacancy_info(dict_with_links_list_g_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f675597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df = pd.DataFrame(columns=['name', 'salary_from', 'salary_to', 'salary_currency', 'salary_gross',\n",
    "       'experience_name', 'schedule_name', 'employment_name', 'description',\n",
    "       'key_skills', 'employer', 'published_at', 'url', 'views', 'type'])\n",
    "for key in all_df:\n",
    "    best_df = pd.concat([best_df, all_df[key]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fa5564bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = pd.DataFrame()\n",
    "for key in all_df:\n",
    "    t = count_skills(all_df[key].key_skills).assign(type = key)\n",
    "    skills = pd.concat([t, skills])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7e10c46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_skills</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SQL</th>\n",
       "      <td>54</td>\n",
       "      <td>BI аналитик</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>30</td>\n",
       "      <td>BI аналитик</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Power BI</th>\n",
       "      <td>28</td>\n",
       "      <td>BI аналитик</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>25</td>\n",
       "      <td>BI аналитик</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MS SQL</th>\n",
       "      <td>20</td>\n",
       "      <td>BI аналитик</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Казначейство</th>\n",
       "      <td>1</td>\n",
       "      <td>Системный аналитик</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Финансовый рынок</th>\n",
       "      <td>1</td>\n",
       "      <td>Системный аналитик</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Депозитарная деятельность</th>\n",
       "      <td>1</td>\n",
       "      <td>Системный аналитик</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Маркетинговые исследования</th>\n",
       "      <td>1</td>\n",
       "      <td>Системный аналитик</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Модели данных</th>\n",
       "      <td>1</td>\n",
       "      <td>Системный аналитик</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3444 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            num_skills                type\n",
       "SQL                                 54         BI аналитик\n",
       "l                                   30         BI аналитик\n",
       "Power BI                            28         BI аналитик\n",
       "Python                              25         BI аналитик\n",
       "MS SQL                              20         BI аналитик\n",
       "...                                ...                 ...\n",
       "Казначейство                         1  Системный аналитик\n",
       "Финансовый рынок                     1  Системный аналитик\n",
       "Депозитарная деятельность            1  Системный аналитик\n",
       "Маркетинговые исследования           1  Системный аналитик\n",
       "Модели данных                        1  Системный аналитик\n",
       "\n",
       "[3444 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4bc129b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные загружены на лист аналитика\n"
     ]
    }
   ],
   "source": [
    "upload_df(best_df, 'аналитика', create_sheet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "548e5705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1DawPp9-eSygPpFe95pgOtVLF4x6lUaimtaH0ykg0DDA',\n",
       " 'tableRange': \"'аналитика_skills'!A1:C1\",\n",
       " 'updates': {'spreadsheetId': '1DawPp9-eSygPpFe95pgOtVLF4x6lUaimtaH0ykg0DDA',\n",
       "  'updatedRange': \"'аналитика_skills'!A2:C3445\",\n",
       "  'updatedRows': 3444,\n",
       "  'updatedColumns': 3,\n",
       "  'updatedCells': 10332}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = work_table.add_worksheet(title='аналитика_skills', rows=100, cols=20)\n",
    "worksheet = work_table.worksheet('аналитика_skills')\n",
    "worksheet.append_row(skills.reset_index().columns.tolist(), value_input_option='USER_ENTERED')\n",
    "worksheet.append_rows(skills.reset_index().values.tolist(), value_input_option='USER_ENTERED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f04b224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd92c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from airflow.decorators import dag, task\n",
    "import pandahouse as ph\n",
    "import telegram\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "\n",
    "connection = {'host': 'https://clickhouse.lab.karpov.courses',\n",
    "                      'database':'simulator_20221120',\n",
    "                      'user':'student', \n",
    "                      'password':'dpo_python_2020'\n",
    "                     }\n",
    "\n",
    "from matplotlib import style\n",
    "sns.set_theme(({**style.library[\"fivethirtyeight\"]}))\n",
    "plt.rcParams[\"figure.figsize\"] = (15,8)\n",
    "\n",
    "\n",
    "my_token = '5831544767:AAE-9VA_reObxmIb_FDZYeh9N4TiCslx-yc' \n",
    "bot = telegram.Bot(token=my_token) \n",
    "\n",
    "chat_id = -817095409\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'd-merinov-24',\n",
    "    'depends_on_past': False,\n",
    "    'retries': 2,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "    'start_date': datetime(2022, 12, 16),\n",
    "    'schedule_interval': '0 11 * * *'\n",
    "    }\n",
    "\n",
    "@dag(default_args=default_args, catchup=False)\n",
    "def lesson_7_dag_2_merinov():\n",
    "\n",
    "    @task()\n",
    "    def get_dau_df_2():\n",
    "        query = '''\n",
    "                    SELECT COUNT (DISTINCT user_id ) as uniq_users,\n",
    "                    day, os, gender, age, source \n",
    "                    FROM (\n",
    "\n",
    "                            SELECT user_id,\n",
    "                              toStartOfDay(toDateTime(time)) AS  day, os, gender, age, source \n",
    "                            FROM simulator_20221120.feed_actions \n",
    "                            GROUP BY user_id, day,os, gender, age, source \n",
    "                            HAVING day > (today()-1) - 7 and day != today()\n",
    "\n",
    "                            UNION ALL\n",
    "\n",
    "                            SELECT user_id,\n",
    "                              toStartOfDay(toDateTime(time)) AS  day, os, gender, age, source \n",
    "                            FROM simulator_20221120.message_actions \n",
    "                            GROUP BY user_id, day, os, gender, age, source \n",
    "                            HAVING day > (today()-1) - 7 and day != today()\n",
    "                              )\n",
    "                    GROUP BY day, os, gender, age, source \n",
    "                '''\n",
    "        dau_df = ph.read_clickhouse(query=query, connection=connection)\n",
    "        dau_df.day = dau_df.day.dt.date\n",
    "        return dau_df\n",
    "\n",
    "    @task()\n",
    "    def get_dau_info(dau_df):\n",
    "        dau = dau_df.groupby('day', as_index=False).agg({'uniq_users':'sum'})\n",
    "        dau['growth_rate'] = dau.uniq_users.pct_change()\n",
    "\n",
    "        date = dau.day.max()\n",
    "        dau_value = dau.query('day == @dau_df.day.max()').iloc[0][1]\n",
    "        diff = round((dau.query('day == @dau_df.day.max()').iloc[0][2]*100), 2)\n",
    "\n",
    "        if diff > 0:\n",
    "            change = 'больше'\n",
    "        else:\n",
    "            change = 'меньше'\n",
    "\n",
    "        title = '👥<b>Пользователи</b>'\n",
    "\n",
    "        text_1 = f'За {date} DAU составил {dau_value}, что на {abs(diff)}% {change}, чем днем ранее.'\n",
    "\n",
    "        source = dau_df.groupby(['day', 'source'], as_index=False)\\\n",
    "                    .agg({'uniq_users':'sum'})\\\n",
    "                    .sort_values('day')\n",
    "        source['ads_growth_rate'] = source.query('source == \"ads\"').uniq_users.pct_change()\n",
    "        source['organic_growth_rate'] = source.query('source == \"organic\"').uniq_users.pct_change()\n",
    "\n",
    "        ads_users = source.query('day == @dau_df.day.max() and source == \"ads\"').iloc[0][2]\n",
    "        organic_users = source.query('day == @dau_df.day.max() and source == \"organic\"').iloc[0][2]\n",
    "\n",
    "        ads_growth = round(source.query('day == @dau_df.day.max() and source == \"ads\"').iloc[0][3] * 100, 2)\n",
    "        organic_growth = round(source.query('day == @dau_df.day.max() and source == \"organic\"').iloc[0][4] * 100, 2)\n",
    "\n",
    "        text_2 = f'Их них {ads_users} ({ads_growth}% к пред. дню) пользователей с рекламы и {organic_users} ({organic_growth}% к пред. дню) с органического трафика. '\n",
    "\n",
    "        os = dau_df.groupby(['day', 'os'], as_index=False)\\\n",
    "                    .agg({'uniq_users':'sum'})\\\n",
    "                    .sort_values('day')\n",
    "        os['androind_growth_rate'] = os.query('os == \"Android\"').uniq_users.pct_change()\n",
    "        os['iOS_growth_rate'] = os.query('os == \"iOS\"').uniq_users.pct_change()\n",
    "\n",
    "        android_users = os.query('day == @dau_df.day.max() and os == \"Android\"').iloc[0][2]\n",
    "        ios_users = os.query('day == @dau_df.day.max() and os == \"iOS\"').iloc[0][2]\n",
    "\n",
    "        android_growth = round(os.query('day == @dau_df.day.max() and os == \"Android\"').iloc[0][3] * 100, 2)\n",
    "        ios_growth = round(os.query('day == @dau_df.day.max() and os == \"iOS\"').iloc[0][4] * 100, 2)\n",
    "\n",
    "        text_3 = f'Лентой воспользовались {android_users} ({android_growth}% к пред. дню) пользователей с Android и {ios_users} пользователей с iOS({ios_growth}%  к пред. дню). '\n",
    "\n",
    "        return title + '\\n' + '\\n' + text_1 + '\\n' + text_2 + '\\n' + text_3 + '\\n'\n",
    "\n",
    "    @task()\n",
    "    def get_df_new_users():\n",
    "        query = '''with mess as (Select    user_id,\n",
    "                               min(toDate(time)) as bd,\n",
    "                           os, gender, age, source\n",
    "                            From simulator_20221120.message_actions \n",
    "                            Group by user_id, os, gender, age, source\n",
    "                            having bd > (today()-1) - 7 and bd != today()),\n",
    "                    feed as \n",
    "                                (Select    user_id,\n",
    "                                           min(toDate(time)) as bd,\n",
    "                                           os, gender, age, source\n",
    "                                From simulator_20221120.feed_actions \n",
    "                                Group by user_id, os, gender, age, source\n",
    "                                having bd > (today()-1) - 7 and bd != today())\n",
    "\n",
    "            select count(distinct user_id) as users, bd, os,gender, age, source from feed l\n",
    "            full Join mess r on l.user_id = r.user_id \n",
    "                        AND l.bd=r.bd \n",
    "                        AND l.os=r.os \n",
    "                        AND l.gender=r.gender \n",
    "                        AND l.age=r.age \n",
    "                        AND l.source = r.source\n",
    "            group by bd, os,gender, age, source\n",
    "            ORDER BY bd DESC'''\n",
    "        df_new_users = ph.read_clickhouse(query=query, connection=connection)\n",
    "        df_new_users.bd = df_new_users.bd.dt.date\n",
    "        return df_new_users\n",
    "    \n",
    "    @task()\n",
    "    def get_info_new_users(df_new_users):\n",
    "\n",
    "        new_users = df_new_users.groupby('bd', as_index=False).agg({'users':'sum'})\n",
    "        new_users['growth_rate'] = new_users.users.pct_change()\n",
    "\n",
    "        date = new_users.bd.max()\n",
    "        new_users_value = new_users.query('bd == @df_new_users.bd.max()').iloc[0][1]\n",
    "        diff = round((new_users.query('bd == @df_new_users.bd.max()').iloc[0][2]*100), 2)\n",
    "\n",
    "        if diff > 0:\n",
    "            change = 'больше'\n",
    "        else:\n",
    "            change = 'меньше'\n",
    "\n",
    "        title = \"🆕<b>Новые пользователи</b>\"\n",
    "\n",
    "        text_1 = f'За день пришло {new_users_value} новых пользователей, что на {abs(diff)}% {change}, чем днем ранее.'\n",
    "\n",
    "        source = df_new_users.groupby(['bd', 'source'], as_index=False)\\\n",
    "                    .agg({'users':'sum'})\\\n",
    "                    .sort_values('bd')\n",
    "\n",
    "        source['ads_growth_rate'] = source.query('source == \"ads\"').users.pct_change()\n",
    "        source['organic_growth_rate'] = source.query('source == \"organic\"').users.pct_change()\n",
    "\n",
    "        ads_users = source.query('bd == @df_new_users.bd.max() and source == \"ads\"').iloc[0][2]\n",
    "        organic_users = source.query('bd == @df_new_users.bd.max() and source == \"organic\"').iloc[0][2]\n",
    "\n",
    "        ads_growth = round(source.query('bd == @df_new_users.bd.max() and source == \"ads\"').iloc[0][3] * 100, 2)\n",
    "        organic_growth = round(source.query('bd == @df_new_users.bd.max() and source == \"organic\"').iloc[0][4] * 100, 2)\n",
    "\n",
    "        text_2 = f'Их них {ads_users} ({ads_growth}% к пред. дню) пользователей с рекламы и {organic_users} ({organic_growth}% к пред. дню) с органического трафика. '\n",
    "\n",
    "        df_new_users['age_cut'] = pd.cut(df_new_users.age, [0, 15, 21, 27, 35, 45, 60, 70, 150])\n",
    "\n",
    "        male = df_new_users.groupby(['gender', 'bd'])['users'].sum()\\\n",
    "                        .to_frame().reset_index()\\\n",
    "                        .query('bd == @df_new_users.bd.max() and gender == 1')\\\n",
    "                        .iloc[0][2]\n",
    "        female = df_new_users.groupby(['gender', 'bd'])['users'].sum()\\\n",
    "                        .to_frame().reset_index()\\\n",
    "                        .query('bd == @df_new_users.bd.max() and gender == 0')\\\n",
    "                        .iloc[0][2]\n",
    "\n",
    "        age = df_new_users.groupby(['age_cut', 'bd'])['users'].sum()\\\n",
    "                        .to_frame().reset_index()\\\n",
    "                        .sort_values(['bd', 'users'], ascending=False)\\\n",
    "                        .iloc[0][0]\n",
    "        male_share = round(male/(female+male)*100)\n",
    "        female_share = round(female/(female+male)*100)\n",
    "\n",
    "        text_3 = f'Среди новых пользователей мужчин - {male} ({male_share}%) человек, девушек - {female} ({female_share}%) человек.  Наибольшее число новых пользователей в возрасте {age}'\n",
    "\n",
    "\n",
    "        return title+ '\\n' + '\\n' + text_1 + '\\n' + text_2 + '\\n' + text_3\n",
    "    \n",
    "    @task()\n",
    "    def get_likes_views_df():\n",
    "            query = '''SELECT toStartOfDay(toDateTime(time)) AS day,\n",
    "                           count(user_id) as actions,\n",
    "                           action \n",
    "                      FROM simulator_20221120.feed_actions\n",
    "                      WHERE day > (today()-1) - 7 and day != today()\n",
    "                      GROUP BY toStartOfDay(toDateTime(time)), action\n",
    "                      ORDER BY day DESC '''\n",
    "\n",
    "            likes_views_df = ph.read_clickhouse(query=query, connection=connection)\n",
    "            likes_views_df.day = likes_views_df.day.dt.date\n",
    "            return likes_views_df\n",
    "\n",
    "    @task()\n",
    "    def get_messages_df():\n",
    "            query = '''SELECT toStartOfDay(toDateTime(time)) AS day,\n",
    "                           count(user_id) as messages\n",
    "                    FROM simulator_20221120.message_actions\n",
    "                    WHERE day > (today()-1) - 7 and day != today()\n",
    "                    GROUP BY toStartOfDay(toDateTime(time))\n",
    "                    ORDER BY day DESC'''\n",
    "            messages_df = ph.read_clickhouse(query=query, connection=connection)\n",
    "            # messages_df.day = likes_views_df.day.dt.date\n",
    "\n",
    "            return messages_df\n",
    "    @task()\n",
    "    def get_info_likes_views_mess(likes_views_df, messages_df):\n",
    "\n",
    "\n",
    "        actions_df = likes_views_df.groupby(['day', 'action'], as_index=False)\\\n",
    "                    .agg({'actions':'sum'})\\\n",
    "                    .sort_values('day')\n",
    "        actions_df['like_growth_rate'] = actions_df.query('action == \"like\"').actions.pct_change()\n",
    "        actions_df['view_growth_rate'] = actions_df.query('action == \"view\"').actions.pct_change()\n",
    "\n",
    "        likes = actions_df.query('day == @actions_df.day.max() and action == \"like\"').iloc[0][2]\n",
    "        views = actions_df.query('day == @actions_df.day.max() and action == \"view\"').iloc[0][2]\n",
    "\n",
    "        likes_growth = round(actions_df.query('day == @actions_df.day.max() and action == \"like\"').iloc[0][3] * 100, 2)\n",
    "        views_growth = round(actions_df.query('day == @actions_df.day.max() and action == \"view\"').iloc[0][4] * 100, 2)\n",
    "\n",
    "        ctr = round(likes/views, 4)*100\n",
    "\n",
    "        title = \"💖💬<b>Активность</b>\"\n",
    "\n",
    "        text_1 = f'За вчера было поставлено {likes} лайков ({likes_growth}% к пред. дню) и просмотрено {views} постов ({views_growth}% к пред. дню). CTR составил  {ctr}%'\n",
    "\n",
    "        mes_1 = messages_df.sort_values('day', ascending=False).iloc[0][1]\n",
    "        mes_0 = messages_df.sort_values('day', ascending=False).iloc[1][1]\n",
    "\n",
    "        mes_diff = round(mes_1/mes_0 - 1, 2)*100\n",
    "\n",
    "        text_2 = f'Также было отправлено {mes_1} сообщений ({mes_diff}% к пред. дню)'\n",
    "\n",
    "        return title + '\\n'+ '\\n' + text_1 + '\\n' + text_2\n",
    "    \n",
    "    @task()\n",
    "    def send_plot_dau_df(dau_df):\n",
    "        dau_df.day = pd.to_datetime(dau_df[\"day\"])\n",
    "        dau_df = dau_df.sort_values('day')\n",
    "        dau_df.day = dau_df.day.dt.strftime('%d-%m')\n",
    "\n",
    "        plt.subplot(212)\n",
    "        plt.title('Динамика DAU')\n",
    "        sns.lineplot(y = 'uniq_users', x='day', data=dau_df)\n",
    "        plt.subplot(221)\n",
    "        plt.title('Динамика DAU в разбивке по OS')\n",
    "        sns.lineplot(y = dau_df.uniq_users, x=dau_df.day, hue=dau_df.os)\n",
    "        plt.subplot(222)\n",
    "        plt.title('Динамика DAU в разбивке по Source')\n",
    "        sns.lineplot(y = dau_df.uniq_users, x=dau_df.day, hue=dau_df.source)\n",
    "\n",
    "        plot_object = io.BytesIO()\n",
    "        plt.savefig(plot_object)\n",
    "        plot_object.seek(0)\n",
    "        plot_object.name = 'dau.png'\n",
    "        plt.close()\n",
    "        bot.sendPhoto(chat_id=chat_id, photo=plot_object, parse_mode='HTML')\n",
    "        \n",
    "    @task()\n",
    "    def send_plot_new_users_df(df_new_users):\n",
    "        df_new_users.bd = pd.to_datetime(df_new_users.bd)\n",
    "        df_new_users = df_new_users.sort_values('bd').query('bd > \"1971-01-01\"')\n",
    "        df_new_users.bd = df_new_users.bd.dt.strftime('%d-%m')\n",
    "\n",
    "\n",
    "        plt.subplot(212)\n",
    "        plt.title('динамика привлечения новых пользователей')\n",
    "        sns.lineplot(y = 'users', x='bd', data=df_new_users)\n",
    "        plt.subplot(221)\n",
    "        plt.title('Новые пользователи в разрезе OS')\n",
    "        sns.lineplot(y = 'users', x='bd', hue='os', data=df_new_users)\n",
    "        plt.subplot(222)\n",
    "        plt.title('Новые пользователи в разрезе Source')\n",
    "        sns.lineplot(y = 'users', x='bd', hue='source', data=df_new_users)\n",
    "\n",
    "        plot_object = io.BytesIO()\n",
    "        plt.savefig(plot_object)\n",
    "        plot_object.seek(0)\n",
    "        plot_object.name = 'dau.png'\n",
    "        plt.close()\n",
    "        bot.sendPhoto(chat_id=chat_id, photo=plot_object, parse_mode='HTML')\n",
    "        \n",
    "    @task()\n",
    "    def send_plot_likes_views_df(likes_views_df, messages_df):\n",
    "        likes_views_df.day = pd.to_datetime(likes_views_df[\"day\"])\n",
    "        likes_views_df = likes_views_df.sort_values('day')\n",
    "        likes_views_df.day = likes_views_df.day.dt.strftime('%d-%m')\n",
    "\n",
    "        messages_df.day = pd.to_datetime(messages_df[\"day\"])\n",
    "        messages_df = messages_df.sort_values('day')\n",
    "        messages_df.day = messages_df.day.dt.strftime('%d-%m')\n",
    "\n",
    "        ctr = likes_views_df.pivot_table(index='day', columns='action', values='actions').reset_index()\n",
    "        ctr['ctr'] = ctr.like / ctr.view\n",
    "        ctr['ctr'] = ctr.ctr.mul(100).round(2)\n",
    "\n",
    "        plt.subplot(212)\n",
    "        plt.title('Динамика CTR, %')\n",
    "        sns.lineplot(y = 'ctr', x='day', data=ctr)\n",
    "        plt.subplot(221)\n",
    "        plt.title('Активность в ленте')\n",
    "        sns.lineplot(y = 'actions', x='day', hue='action', data=likes_views_df)\n",
    "        plt.subplot(222)\n",
    "        plt.title('Кол-во отправленных сообщений')\n",
    "        sns.lineplot(y = 'messages', x='day', data=messages_df)\n",
    "\n",
    "        plot_object = io.BytesIO()\n",
    "        plt.savefig(plot_object)\n",
    "        plot_object.seek(0)\n",
    "        plot_object.name = 'dau.png'\n",
    "        plt.close()\n",
    "        bot.sendPhoto(chat_id=chat_id, photo=plot_object, parse_mode='HTML')\n",
    "        \n",
    "    @task()\n",
    "    def send_message(title):\n",
    "        bot.sendMessage(chat_id=chat_id, text=title, parse_mode='HTML')\n",
    "        \n",
    "    @task()\n",
    "    def send_message_title():\n",
    "        ds = context['ds']\n",
    "        bot.sendMessage(chat_id=chat_id, text=f\"📄<b>Ежедневный отчет по ленте новостей, и по сервису отправки сообщений. Дата: {ds}</b>\", parse_mode='HTML')\n",
    "    \n",
    "    send_message_title()\n",
    "    dau_df = get_dau_df_2()\n",
    "    title_1 = get_dau_info(dau_df)\n",
    "    send_message(title_1)\n",
    "    send_plot_dau_df(dau_df)\n",
    "    df_new_users = get_df_new_users()\n",
    "    title_2 = get_info_new_users(df_new_users)\n",
    "    send_message(title_2)\n",
    "    send_plot_new_users_df(df_new_users)\n",
    "    likes_views_df = get_likes_views_df()\n",
    "    messages_df = get_messages_df()\n",
    "    title_3 = get_info_likes_views_mess(likes_views_df, messages_df)\n",
    "    send_message(title_3)\n",
    "    send_plot_likes_views_df(likes_views_df, messages_df)\n",
    "    \n",
    "lesson_7_dag_2_merinov = lesson_7_dag_2_merinov()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
